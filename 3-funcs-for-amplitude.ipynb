{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import time\n",
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Connect and download from Amplitude"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "597acde59372d854"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def download_from_amplitude(api_key, secret_key, date_start, date_end, file_name='amplitude_data',url=\"https://amplitude.com/api/2/export\"):\n",
    "    \"\"\"\n",
    "    Connects to the Amplitude server, downloads RAW data for the specified period in json format and saves it to a zip file.\n",
    "    Note: zip file will be saved to the root folder.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): Amplitude API key.\n",
    "        secret_key (str): Amplitude secret key.\n",
    "        date_start (str): Start date in the format YYYYMMDD.\n",
    "        date_end (str): End date in the format YYYYMMDD.\n",
    "        file_name (str, optional): Name of the zip file. Defaults to 'amplitude_data'.\n",
    "        url (str, optional): Amplitude server url. Defaults to \"https://amplitude.com/api/2/export\".\n",
    "        \n",
    "    Returns:\n",
    "        str: Status message of the function. If the function is successful, it returns the message 'Download completed' and saves the data to the amplitude_data.zip file. If the function fails, it returns the message 'Download failed'. \n",
    "    \"\"\"\n",
    "    credentials = base64.b64encode(f\"{api_key}:{secret_key}\".encode())\n",
    "    headers = {\"Authorization\": f\"Basic {credentials.decode()}\"}\n",
    "    params = {\"start\": date_start, \"end\": date_end}\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        print('Connected to Amplitude server')\n",
    "        # Simulate downloading progress\n",
    "        print('Downloading data... [          ]', end='', flush=True)\n",
    "        for i in range(10):\n",
    "            time.sleep(0.5)  # Simulate downloading with a delay\n",
    "            print('\\b#', end='', flush=True)\n",
    "        with open(f\"{file_name}_{date_start}_{date_end}.zip\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print('\\nAmplitude data downloaded and saved to zip file:', f\"{file_name}_{date_start}_{date_end}.zip\")\n",
    "        return 'Download completed'\n",
    "    else:\n",
    "        print('Error:', response.text)\n",
    "        return 'Download failed'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac43632f3a0a630"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "api_key = \"YOUR_API_KEY\n",
    "secret_key = \"YOUR_SECRET_KEY\"\n",
    "start_date = \"20230817\"\n",
    "end_date = \"20230818\"\n",
    "\n",
    "result = download_from_amplitude(api_key, secret_key, start_date, end_date)\n",
    "print(result)  # Print the status message returned by the function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d20318dc9822a623"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract zip file and convert JSON to the Pandas Dataframe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29b39107c15a2d55"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unzip_json_to_df(zip_file, folder_name='amplitude_data'):\n",
    "    \"\"\"\n",
    "    Extracts the zip file and converts the JSON files to the Pandas Dataframe.\n",
    "    Note: zip file must contain only JSON files. And stored in the root folder.\n",
    "    \n",
    "    Args:\n",
    "        zip_file (str): Name of the zip file.\n",
    "        folder_name (str, optional): Name of the folder where the data will be extracted. Defaults to 'amplitude_data'.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Pandas Dataframe with the Amplitude data.\n",
    "    \"\"\" \n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(folder_name)\n",
    "    print('\\nAmplitude data extracted to the folder:', folder_name)\n",
    "    print('Creating Dataframe... [          ]', end='', flush=True)\n",
    "    for i in range(10):\n",
    "        time.sleep(0.5) \n",
    "        print('\\b#', end='', flush=True)\n",
    "    df_func_combined = pd.DataFrame()\n",
    "    for root, dirs, files in os.walk(folder_name):\n",
    "        for file in files: \n",
    "            if file.endswith('.gz'):\n",
    "                with gzip.open(os.path.join(root, file), 'rb') as f:\n",
    "                    file_func_content = f.read()\n",
    "                    df_func_i = pd.read_json(file_func_content, lines=True)\n",
    "                    df_func_combined = pd.concat([df_func_combined, df_func_i], axis=0)\n",
    "    print('\\nDataframe created (rows, columns):', df_func_combined.shape)\n",
    "    return df_func_combined"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb64933cb9923962"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = unzip_json_to_df('amplitude_data_20230817_20230818.zip', folder_name='amplitude_data1')\n",
    "df2 = unzip_json_to_df('amplitude_data.zip', folder_name='amplitude_data2')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72960f87a43adf44"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concatenate and save to csv file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf214f5a0f624cf2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def concat_df_to_csv(dataframes, csv='amplitude_data.csv'):\n",
    "    \"\"\"\n",
    "    Concatenate a list of DataFrames vertically. And save it to csv file.\n",
    "    Note: csv file will be saved to the root folder.\n",
    "\n",
    "    Args:\n",
    "        dataframes (list): List of pandas DataFrames.\n",
    "        csv (str, optional): Name of the csv file. Defaults to 'amplitude_data.csv'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Concatenated DataFrame.\n",
    "    \"\"\"\n",
    "    concatenated_df = pd.concat(dataframes, axis=0)\n",
    "    concatenated_df.to_csv(csv, index=False)\n",
    "    return print('Data saved to csv file: ' + csv)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3b198a758122f4f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "concat_df_to_csv([df, df2], csv='amplitude_data.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60091dd5d34b78d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
